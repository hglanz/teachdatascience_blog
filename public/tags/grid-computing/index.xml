<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>grid computing on Teach Data Science</title>
    <link>https://teachdatascience.com/tags/grid-computing/</link>
    <description>Recent content in grid computing on Teach Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>(c) 2019 Copyright Teach Data Science</copyright>
    <lastBuildDate>Thu, 11 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://teachdatascience.com/tags/grid-computing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Parallel processing and sparklyr</title>
      <link>https://teachdatascience.com/parallel/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://teachdatascience.com/parallel/</guid>
      <description>Today’s blog entry is on parallel computing. As a data science education blog, our focus is more on how to discuss ideas of parallel computing in the classroom rather than parallel computing for particular research projects. Indeed, at times there seems to be quite a bit of hype around parallel computing when it isn’t particularly necessary or helpful.
In this blog, we’ll perform tasks that are embarassingly parallel which means there is no dependency or communication between the parallel tasks.</description>
    </item>
    
  </channel>
</rss>